# 语义分割实现记录

## 网络构建

1. 加载预训练的网络
2. 修改网络的输出层(替换掉最后的全局平均池化和全连接层)
3. 通过上采样, 将输出层与输入层长宽一致

```python
model_ft = resnet50(pretrained=True)
for param in model_ft.parameters():
    param.requires_grad = False
#去掉最后两层-->添加卷积层-->获得更大的feature map
model_ft = nn.Sequential(*list(model_ft.children())[:-2], 
                             nn.Conv2d(2048,num_classes,kernel_size=1),
                             nn.ConvTranspose2d(num_classes,num_classes, kernel_size=64, padding=16, stride=32)).to(device) 

#双线性插值的上采样, 用来初始化转置卷积层的卷积核
def bilinear_kernel(in_channels, out_channels, kernel_size):
    factor = (kernel_size+1)//2
    if kernel_size%2 == 1:
    	center = factor-1
    else:
    	center = factor-0.5
    og = np.ogrid[:kernel_size,:kernel_size]
    filt = (1-abs(og[0]-center)/factor)*(1-abs(og[1]-center)/factor)
    weight = np.zeros((in_channels,out_channels,
                       kernel_size,kernel_size),
                      dtype='float32')
    weight[range(in_channels),range(out_channels),:, :]=filt
    weight = torch.Tensor(weight)
    weight.requires_grad=True
    return weight
#在全卷积, 将转置卷积层初始化为双线性插值上采样.对于1x1卷积, 采用Xavier随机初始化
nn.init.xavier_normal_(model_ft[-2].weight.data,gain=1)
model_ft[-1].weight.data = bilinear_kernel(num_classes,
                                           num_classes,
                                           64).to(device)
```

## 将颜色转为标签

```python
# 标签中每个RGB颜色的值及其标注的类别
VOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],
                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],
                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],
                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],
                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],
                [0, 64, 128]]

VOC_CLASSES = ['background', 'aeroplane', 'bicycle', 'bird', 'boat',
               'bottle', 'bus', 'car', 'cat', 'chair', 'cow',
               'diningtable', 'dog', 'horse', 'motorbike', 'person',
               'potted plant', 'sheep', 'sofa', 'train', 'tv/monitor']
```

根据公式
$$
VOC\_COLORMAP[0]*255^2+VOC\_COLORMAP*255+VOC\_COLORMAP
$$
将每种RGB色转为特定的类别

```python
#定义两个常量,查找标签中每个像素的类别索引
colormap2label = torch.zeros(256**3,dtype=torch.uint8)
for i, colormap in enumerate(VOC_COLORMAP):
    colormap2label[(colormap[0]*256+colormap[1])*256+colormap[2]]=i
def voc_label_indices(colormap, colormap2label):
    '''
    convert colormap (PIL image) to colormap2label (uint8 tensor)
    :param colormap: seg image
    :param colormap2label: int
    :return:
    '''
    colormap = np.array(colormap.convert("RGB")).astype("int32")
    idx = ((colormap[:,:,0]*256+colormap[:,:,1])*256+colormap[:,:,2])
    return colormap2label[idx]
```

## 将标签转为图像

根据预测label索引, 直接获取对应的RGB值. 即用label替换为对应的COLORMAP

```python
VOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],
                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],
                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],
                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],
                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],
                [0, 64, 128]]
def label2image(pred):
    #pred: [320,480]
    colormap = torch.tensor(VOC_COLORMAP, device=device,dtype=int)
    x = pred.long()
    imgs = (colormap[x,:]).data.cpu().numpy()
    return imgs
```

## 将模型预测结果转为图像

1. 将标准化的值反转为0~255整数
2. 将预测结果从GPU位置转移到CPU上
3. 将预测的label转为对应的RGB值

```python
mean = torch.tensor([0.485,0.456,0.406]).reshape(3,1,1).to(device)
std = torch.tensor([0.229,0.224,0.225]).reshape(3,1,1).to(device)
def visualize_model(model:nn.Module, voc_val, num_images=4):
    was_training = model.training
    model.eval()
    images_so_far = 0
    n, imgs = num_images, []
    with torch.no_grad():
        for i, (inputs, labels) in enumerate(voc_val):
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            pred = torch.argmax(outputs,dim=1)#[b,320,480]
            inputs_nd = (inputs*std+mean).permute(0,2,3,1)*255

            for j in range(num_images):
                images_so_far += 1
                pred1 = label2image(pred[j])#np.array(320,480,3)
                # pred1 = label2image(pred)#np.array(320,480,3)#多张图同时转
                imgs += [inputs_nd[j].data.int().cpu().numpy(), 
                         pred1,
                         label2image(labels[j])]
                if images_so_far == num_images:
                    model.train(mode=was_training)
                    show_images(imgs[::3]+imgs[1::3]+imgs[2::3],3,n)
                    return model
```

## 原图,预label, 真实label显示

```python
def show_images(imgs, num_rows, num_cols, scale=2):
    figsize = (num_cols * scale, num_rows * scale)
    _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)
    for i in range(num_rows):
        for j in range(num_cols):
            axes[i][j].imshow(imgs[i * num_cols + j])
            axes[i][j].axes.get_xaxis().set_visible(False)
            axes[i][j].axes.get_yaxis().set_visible(False)
    plt.pause(0.05)
    return axes
```

![image-20211010154627903](E:\kuisu\typora\深度学习资料\卷积网络\语义分割实现相关工具.assets\image-20211010154627903-16338519982911.png)

